{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re # Regular expression\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import nltk # Natural Language Tool Kit\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>helpfulness</th>\n",
       "      <th>productId</th>\n",
       "      <th>profileName</th>\n",
       "      <th>score</th>\n",
       "      <th>summary</th>\n",
       "      <th>text</th>\n",
       "      <th>time</th>\n",
       "      <th>userId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0/0</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/1</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>4.0</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3/3</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>Karl</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0/0</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  helpfulness   productId                      profileName score  \\\n",
       "0         1/1  B001E4KFG0                       delmartian   5.0   \n",
       "1         0/0  B00813GRG4                           dll pa   1.0   \n",
       "2         1/1  B000LQOCH0  Natalia Corres \"Natalia Corres\"   4.0   \n",
       "3         3/3  B000UA0QIQ                             Karl   2.0   \n",
       "4         0/0  B006K2ZZ7K    Michael D. Bigham \"M. Wassir\"   5.0   \n",
       "\n",
       "                 summary                                               text  \\\n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...   \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...   \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...   \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...   \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...   \n",
       "\n",
       "         time          userId  \n",
       "0  1303862400  A3SGXH7AUHU8GW  \n",
       "1  1346976000  A1D87F6ZCVE5NK  \n",
       "2  1219017600   ABXLMWJIXXAIN  \n",
       "3  1307923200  A395BORC6FGVXV  \n",
       "4  1350777600  A1UQRSCLF8GW1T  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle('./finefood_dataset.pkl')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>summary</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  score                summary  \\\n",
       "0   5.0  Good Quality Dog Food   \n",
       "1   1.0      Not as Advertised   \n",
       "2   4.0  \"Delight\" says it all   \n",
       "3   2.0         Cough Medicine   \n",
       "4   5.0            Great taffy   \n",
       "\n",
       "                                                text  \n",
       "0  I have bought several of the Vitality canned d...  \n",
       "1  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  This is a confection that has been around a fe...  \n",
       "3  If you are looking for the secret ingredient i...  \n",
       "4  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop([\"helpfulness\",\"productId\",\"profileName\", \"time\", \"userId\"], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(568454, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Cleaning\n",
    "\n",
    "credit to: https://github.com/hlamba28/Amazon-Food-Review/blob/master/1.%20Exploratory%20Analysis%20and%20Cleaning/EDA%20and%20Cleaning%20-%20Amazon%20Reviwes.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(395006, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dedup = df.drop_duplicates(subset={'score', 'summary','text'}).copy()\n",
    "df_dedup.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HTML tags "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't know if it's the cactus or the tequila or just the unique combination of ingredients, but the flavour of this hot sauce makes it one of a kind!  We picked up a bottle once on a trip we were on and brought it back home with us and were totally blown away!  When we realized that we simply couldn't find it anywhere in our city we were bummed.<br /><br />Now, because of the magic of the internet, we have a case of the sauce and are ecstatic because of it.<br /><br />If you love hot sauce..I mean really love hot sauce, but don't want a sauce that tastelessly burns your throat, grab a bottle of Tequila Picante Gourmet de Inclan.  Just realize that once you taste it, you will never want to use any other sauce.<br /><br />Thank you for the personal, incredible service! \n",
      "\n",
      "\n",
      "Twizzlers, Strawberry my childhood favorite candy, made in Lancaster Pennsylvania by Y & S Candies, Inc. one of the oldest confectionery Firms in the United States, now a Subsidiary of the Hershey Company, the Company was established in 1845 as Young and Smylie, they also make Apple Licorice Twists, Green Color and Blue Raspberry Licorice Twists, I like them all<br /><br />I keep it in a dry cool place because is not recommended it to put it in the fridge. According to the Guinness Book of Records, the longest Licorice Twist ever made measured 1.200 Feet (370 M) and weighted 100 Pounds (45 Kg) and was made by Y & S Candies, Inc. This Record-Breaking Twist became a Guinness World Record on July 19, 1998. This Product is Kosher! Thank You \n",
      "\n",
      "\n",
      "I bought these for my husband who is currently overseas. He loves these, and apparently his staff likes them also.<br />There are generous amounts of Twizzlers in each 16-ounce bag, and this was well worth the price. <a href=\"http://www.amazon.com/gp/product/B001GVISJM\">Twizzlers, Strawberry, 16-Ounce Bags (Pack of 6)</a> \n",
      "\n",
      "\n",
      "I have lived out of the US for over 7 yrs now, and I so miss my Twizzlers!!  When I go back to visit or someone visits me, I always stock up.  All I can say is YUM!<br />Sell these in Mexico and you will have a faithful buyer, more often than I'm able to buy them right now. \n",
      "\n",
      "\n",
      "Product received is as advertised.<br /><br /><a href=\"http://www.amazon.com/gp/product/B001GVISJM\">Twizzlers, Strawberry, 16-Ounce Bags (Pack of 6)</a> \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for sen in df_dedup['text'].values:\n",
    "    if(len(re.findall('<.*?>', sen))): # Find all strings starting with '<' and ending with '>'\n",
    "        print(sen,\"\\n\\n\")\n",
    "        i += 1\n",
    "    if i == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'down', 'needn', 'weren', 'of', 'i', 'myself', \"wouldn't\", 'will', 'yourself', 'against', 'being', \"didn't\", 'or', 'haven', 'up', \"you'd\", 'the', 'shan', 'who', 'whom', 'just', 'ain', 'now', \"isn't\", \"you've\", 'aren', 'which', 'when', 'had', \"shan't\", 'our', 'd', 'from', 'some', 'is', 's', 'doing', \"shouldn't\", 'if', 'off', 'after', 'all', 'yourselves', 'why', \"doesn't\", 'you', 'any', \"aren't\", 'shouldn', 'there', 'himself', 'don', 've', 'y', 'in', 'between', 'here', 'few', 'above', 'this', 'do', 'because', 'how', 'ourselves', \"don't\", 'didn', 'he', 'under', 'each', 'your', 'other', 'ours', 'her', \"it's\", 'most', 'out', 'be', \"couldn't\", 'yours', 'his', 'own', 'doesn', 'below', 'does', 'such', 'an', 'before', 'should', 'more', 're', 'hadn', 'we', \"haven't\", \"wasn't\", 'to', 'can', \"weren't\", 'herself', 'him', 'by', 'ma', \"won't\", 'until', 'has', 'about', 'll', 'as', 'again', 'but', 'themselves', 'they', \"mightn't\", 'hers', \"mustn't\", 'me', 'hasn', 'into', 'did', 'only', 'wasn', 'been', 'have', 'while', 'over', 'than', \"needn't\", 'on', 'both', \"she's\", 'it', 'that', 'where', 'couldn', 'mustn', 'further', 'was', 'these', 'am', 'm', 'a', 'during', 'very', 'isn', 'its', 'my', 'at', 'same', \"hasn't\", \"you're\", 't', 'she', 'theirs', 'them', 'what', 'wouldn', 'through', 'then', \"you'll\", 'not', 'won', 'are', \"hadn't\", \"should've\", 'and', 'mightn', 'so', 'once', 'having', \"that'll\", 'itself', 'their', 'too', 'with', 'no', 'were', 'for', 'those', 'o', 'nor'}\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english')) #set of stopwords\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sno = nltk.stem.SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to clean the data from the above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning(series):\n",
    "    '''The function takes a Pandas Series object containing text in all the cells\n",
    "       And performs following Preprocessing steps on each cell:\n",
    "       1. Clean text from html tags\n",
    "       2. Clean text from punctuations and special characters\n",
    "       3. Retain only non-numeric Latin characters with lenght > 2\n",
    "       4. Remove stopwords from the sentence\n",
    "       5. Apply lower casing\n",
    "       6. Apply stemming to all the words in the sentence\n",
    "       \n",
    "       Return values:\n",
    "       1. final_string - List of cleaned sentences\n",
    "       2. list_of_sent - List of lists which will be used as input to the W2V model'''\n",
    "    \n",
    "    i = 0\n",
    "    string = \"\"\n",
    "    final_string = []    ## This list will contain cleaned sentences\n",
    "    list_of_sent = []    ## This is a list of lists used as input to the W2V model at a later stage\n",
    "    cleanr = re.compile('<.*?>') # Compile re to remove html tags\n",
    "    \n",
    "    for sent in series.values:\n",
    "        filtered_sent = []\n",
    "        sent = re.sub(cleanr, ' ', sent) # remove html tags\n",
    "        sent = re.sub('[^a-zA-Z0-9\\n]', ' ', sent) # remove special characters\n",
    "        sent = re.sub('\\s+',' ', sent) # replace multiple spaces with single space\n",
    "        sent = sent.lower() # convert all characters to lower case\n",
    "        for word in sent.split():\n",
    "            if word not in stop_words and len(word)>2:\n",
    "                word = sno.stem(word) # Apply Stemming using snowball stemmer\n",
    "                filtered_sent.append(word)\n",
    "        list_of_sent.append(filtered_sent) # This list is used later\n",
    "        string = \" \".join(filtered_sent) # Cleaned sentence\n",
    "        final_string.append(string) # List of cleaned sentences\n",
    "        i+=1\n",
    "    return final_string, list_of_sent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Cleaning\n",
      "\n",
      "\n",
      "I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labrador is finicky and she appreciates this product better than  most. \n",
      "\n",
      "\n",
      "Product arrived labeled as Jumbo Salted Peanuts...the peanuts were actually small sized unsalted. Not sure if this was an error or if the vendor intended to represent the product as \"Jumbo\". \n",
      "\n",
      "\n",
      "This is a confection that has been around a few centuries.  It is a light, pillowy citrus gelatin with nuts - in this case Filberts. And it is cut into tiny squares and then liberally coated with powdered sugar.  And it is a tiny mouthful of heaven.  Not too chewy, and very flavorful.  I highly recommend this yummy treat.  If you are familiar with the story of C.S. Lewis' \"The Lion, The Witch, and The Wardrobe\" - this is the treat that seduces Edmund into selling out his Brother and Sisters to the Witch. \n",
      "\n",
      "\n",
      "If you are looking for the secret ingredient in Robitussin I believe I have found it.  I got this in addition to the Root Beer Extract I ordered (which was good) and made some cherry soda.  The flavor is very medicinal. \n",
      "\n",
      "\n",
      "Great taffy at a great price.  There was a wide assortment of yummy taffy.  Delivery was very quick.  If your a taffy lover, this is a deal. \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Before Cleaning\\n\\n')\n",
    "for x in df_dedup['text'].iloc[:5].values:\n",
    "    print(x,\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After cleaning \n",
      "\n",
      "\n",
      "bought sever vital can dog food product found good qualiti product look like stew process meat smell better labrador finicki appreci product better \n",
      "\n",
      "\n",
      "product arriv label jumbo salt peanut peanut actual small size unsalt sure error vendor intend repres product jumbo \n",
      "\n",
      "\n",
      "confect around centuri light pillowi citrus gelatin nut case filbert cut tini squar liber coat powder sugar tini mouth heaven chewi flavor high recommend yummi treat familiar stori lewi lion witch wardrob treat seduc edmund sell brother sister witch \n",
      "\n",
      "\n",
      "look secret ingredi robitussin believ found got addit root beer extract order good made cherri soda flavor medicin \n",
      "\n",
      "\n",
      "great taffi great price wide assort yummi taffi deliveri quick taffi lover deal \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"After cleaning \\n\\n\")\n",
    "final_string, list_of_sent = data_cleaning(df_dedup['text'].iloc[:5])\n",
    "for x in final_string:\n",
    "    print(x,\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the whole texts in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time takes in seconds = 208.69525051116943\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "df_dedup['text_cleaned'], list_of_sent = data_cleaning(df_dedup['text'])\n",
    "df_dedup['summary_cleaned'], list_of_sent = data_cleaning(df_dedup['summary'])\n",
    "end = time.time()\n",
    "print(\"Time takes in seconds =\", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>summary</th>\n",
       "      <th>text</th>\n",
       "      <th>text_cleaned</th>\n",
       "      <th>summary_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>bought sever vital can dog food product found ...</td>\n",
       "      <td>good qualiti dog food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>product arriv label jumbo salt peanut peanut a...</td>\n",
       "      <td>advertis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>confect around centuri light pillowi citrus ge...</td>\n",
       "      <td>delight say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "      <td>look secret ingredi robitussin believ found go...</td>\n",
       "      <td>cough medicin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>great taffi great price wide assort yummi taff...</td>\n",
       "      <td>great taffi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  score                summary  \\\n",
       "0   5.0  Good Quality Dog Food   \n",
       "1   1.0      Not as Advertised   \n",
       "2   4.0  \"Delight\" says it all   \n",
       "3   2.0         Cough Medicine   \n",
       "4   5.0            Great taffy   \n",
       "\n",
       "                                                text  \\\n",
       "0  I have bought several of the Vitality canned d...   \n",
       "1  Product arrived labeled as Jumbo Salted Peanut...   \n",
       "2  This is a confection that has been around a fe...   \n",
       "3  If you are looking for the secret ingredient i...   \n",
       "4  Great taffy at a great price.  There was a wid...   \n",
       "\n",
       "                                        text_cleaned        summary_cleaned  \n",
       "0  bought sever vital can dog food product found ...  good qualiti dog food  \n",
       "1  product arriv label jumbo salt peanut peanut a...               advertis  \n",
       "2  confect around centuri light pillowi citrus ge...            delight say  \n",
       "3  look secret ingredi robitussin believ found go...          cough medicin  \n",
       "4  great taffi great price wide assort yummi taff...            great taffi  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dedup.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dedup['summary'] = df_dedup['summary'].str.lower()\n",
    "df_dedup['text'] = df_dedup['text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dedup[\"word_counts_summary\"] = df_dedup[\"summary\"].apply(lambda x: len(x.split()))\n",
    "df_dedup[\"word_counts_text\"] = df_dedup[\"text\"].apply(lambda x: len(x.split()))\n",
    "df_dedup[\"word_counts_summary_cleaned\"] = df_dedup[\"summary_cleaned\"].apply(lambda x: len(x.split()))\n",
    "df_dedup[\"word_counts_text_cleaned\"] = df_dedup[\"text_cleaned\"].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>summary</th>\n",
       "      <th>text</th>\n",
       "      <th>text_cleaned</th>\n",
       "      <th>summary_cleaned</th>\n",
       "      <th>word_counts_summary</th>\n",
       "      <th>word_counts_text</th>\n",
       "      <th>word_counts_summary_cleaned</th>\n",
       "      <th>word_counts_text_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>good quality dog food</td>\n",
       "      <td>i have bought several of the vitality canned d...</td>\n",
       "      <td>bought sever vital can dog food product found ...</td>\n",
       "      <td>good qualiti dog food</td>\n",
       "      <td>4</td>\n",
       "      <td>48</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>not as advertised</td>\n",
       "      <td>product arrived labeled as jumbo salted peanut...</td>\n",
       "      <td>product arriv label jumbo salt peanut peanut a...</td>\n",
       "      <td>advertis</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>\"delight\" says it all</td>\n",
       "      <td>this is a confection that has been around a fe...</td>\n",
       "      <td>confect around centuri light pillowi citrus ge...</td>\n",
       "      <td>delight say</td>\n",
       "      <td>4</td>\n",
       "      <td>94</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>cough medicine</td>\n",
       "      <td>if you are looking for the secret ingredient i...</td>\n",
       "      <td>look secret ingredi robitussin believ found go...</td>\n",
       "      <td>cough medicin</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>great taffy</td>\n",
       "      <td>great taffy at a great price.  there was a wid...</td>\n",
       "      <td>great taffi great price wide assort yummi taff...</td>\n",
       "      <td>great taffi</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  score                summary  \\\n",
       "0   5.0  good quality dog food   \n",
       "1   1.0      not as advertised   \n",
       "2   4.0  \"delight\" says it all   \n",
       "3   2.0         cough medicine   \n",
       "4   5.0            great taffy   \n",
       "\n",
       "                                                text  \\\n",
       "0  i have bought several of the vitality canned d...   \n",
       "1  product arrived labeled as jumbo salted peanut...   \n",
       "2  this is a confection that has been around a fe...   \n",
       "3  if you are looking for the secret ingredient i...   \n",
       "4  great taffy at a great price.  there was a wid...   \n",
       "\n",
       "                                        text_cleaned        summary_cleaned  \\\n",
       "0  bought sever vital can dog food product found ...  good qualiti dog food   \n",
       "1  product arriv label jumbo salt peanut peanut a...               advertis   \n",
       "2  confect around centuri light pillowi citrus ge...            delight say   \n",
       "3  look secret ingredi robitussin believ found go...          cough medicin   \n",
       "4  great taffi great price wide assort yummi taff...            great taffi   \n",
       "\n",
       "   word_counts_summary  word_counts_text  word_counts_summary_cleaned  \\\n",
       "0                    4                48                            4   \n",
       "1                    3                31                            1   \n",
       "2                    4                94                            2   \n",
       "3                    2                41                            2   \n",
       "4                    2                27                            2   \n",
       "\n",
       "   word_counts_text_cleaned  \n",
       "0                        23  \n",
       "1                        18  \n",
       "2                        39  \n",
       "3                        18  \n",
       "4                        13  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dedup.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanatory analysis of the word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"5\" halign=\"left\">word_counts_summary</th>\n",
       "      <th colspan=\"5\" halign=\"left\">word_counts_text</th>\n",
       "      <th colspan=\"5\" halign=\"left\">word_counts_summary_cleaned</th>\n",
       "      <th colspan=\"5\" halign=\"left\">word_counts_text_cleaned</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sum</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>sum</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>sum</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>sum</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>4.213861</td>\n",
       "      <td>153827</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>2.834258</td>\n",
       "      <td>82.701466</td>\n",
       "      <td>3019017</td>\n",
       "      <td>2149</td>\n",
       "      <td>3</td>\n",
       "      <td>77.717930</td>\n",
       "      <td>2.676674</td>\n",
       "      <td>97712</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>1.665292</td>\n",
       "      <td>40.007396</td>\n",
       "      <td>1460470</td>\n",
       "      <td>1026</td>\n",
       "      <td>1</td>\n",
       "      <td>38.888307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>4.452269</td>\n",
       "      <td>92812</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>2.731847</td>\n",
       "      <td>90.323371</td>\n",
       "      <td>1882881</td>\n",
       "      <td>1612</td>\n",
       "      <td>6</td>\n",
       "      <td>81.136660</td>\n",
       "      <td>2.671304</td>\n",
       "      <td>55686</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>1.624054</td>\n",
       "      <td>43.397055</td>\n",
       "      <td>904655</td>\n",
       "      <td>816</td>\n",
       "      <td>2</td>\n",
       "      <td>40.478574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>4.723060</td>\n",
       "      <td>140955</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>2.816306</td>\n",
       "      <td>96.249497</td>\n",
       "      <td>2872470</td>\n",
       "      <td>3432</td>\n",
       "      <td>7</td>\n",
       "      <td>88.777909</td>\n",
       "      <td>2.843352</td>\n",
       "      <td>84857</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1.676644</td>\n",
       "      <td>46.181410</td>\n",
       "      <td>1378238</td>\n",
       "      <td>1930</td>\n",
       "      <td>2</td>\n",
       "      <td>44.282302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>4.390628</td>\n",
       "      <td>246784</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>2.690685</td>\n",
       "      <td>91.973544</td>\n",
       "      <td>5169557</td>\n",
       "      <td>2061</td>\n",
       "      <td>6</td>\n",
       "      <td>87.579048</td>\n",
       "      <td>3.015123</td>\n",
       "      <td>169471</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>1.587675</td>\n",
       "      <td>44.721743</td>\n",
       "      <td>2513675</td>\n",
       "      <td>1066</td>\n",
       "      <td>2</td>\n",
       "      <td>43.576232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>3.899890</td>\n",
       "      <td>981228</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>2.457054</td>\n",
       "      <td>73.971948</td>\n",
       "      <td>18611638</td>\n",
       "      <td>2520</td>\n",
       "      <td>3</td>\n",
       "      <td>72.373733</td>\n",
       "      <td>2.808894</td>\n",
       "      <td>706729</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>1.522305</td>\n",
       "      <td>36.364656</td>\n",
       "      <td>9149493</td>\n",
       "      <td>1527</td>\n",
       "      <td>0</td>\n",
       "      <td>36.479660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      word_counts_summary                           word_counts_text  \\\n",
       "                     mean     sum max min       std             mean   \n",
       "score                                                                  \n",
       "1.0              4.213861  153827  29   1  2.834258        82.701466   \n",
       "2.0              4.452269   92812  27   1  2.731847        90.323371   \n",
       "3.0              4.723060  140955  26   1  2.816306        96.249497   \n",
       "4.0              4.390628  246784  31   1  2.690685        91.973544   \n",
       "5.0              3.899890  981228  42   1  2.457054        73.971948   \n",
       "\n",
       "                                     word_counts_summary_cleaned              \\\n",
       "            sum   max min        std                        mean     sum max   \n",
       "score                                                                          \n",
       "1.0     3019017  2149   3  77.717930                    2.676674   97712  16   \n",
       "2.0     1882881  1612   6  81.136660                    2.671304   55686  16   \n",
       "3.0     2872470  3432   7  88.777909                    2.843352   84857  14   \n",
       "4.0     5169557  2061   6  87.579048                    3.015123  169471  16   \n",
       "5.0    18611638  2520   3  72.373733                    2.808894  706729  17   \n",
       "\n",
       "                    word_counts_text_cleaned                                \n",
       "      min       std                     mean      sum   max min        std  \n",
       "score                                                                       \n",
       "1.0     0  1.665292                40.007396  1460470  1026   1  38.888307  \n",
       "2.0     0  1.624054                43.397055   904655   816   2  40.478574  \n",
       "3.0     0  1.676644                46.181410  1378238  1930   2  44.282302  \n",
       "4.0     0  1.587675                44.721743  2513675  1066   2  43.576232  \n",
       "5.0     0  1.522305                36.364656  9149493  1527   0  36.479660  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dedup.groupby('score').agg(['mean', 'sum', 'max', 'min', 'std'])[['word_counts_summary','word_counts_text', 'word_counts_summary_cleaned', 'word_counts_text_cleaned']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dedup.to_pickle(path=\"./finefood_dataset_cleaned.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
